{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c575a0f3",
   "metadata": {},
   "source": [
    "# üè• Enhanced Medical NER Training - Production-Ready\n",
    "## Advanced Named Entity Recognition for French Medical Documents\n",
    "\n",
    "**Objectives:**\n",
    "- üéØ Train a high-performance medical NER model\n",
    "- üá´üá∑ Optimized for French medical terminology\n",
    "- üìä 100+ diverse training samples across 12 entity types\n",
    "- üöÄ CamemBERT-based (French-optimized BERT)\n",
    "- üìà Advanced evaluation with per-entity metrics\n",
    "- üíæ Production deployment package\n",
    "\n",
    "**Entity Types:**\n",
    "`DISEASE` | `MEDICATION` | `SYMPTOM` | `DOSAGE` | `DATE` | `PROCEDURE` | `ANATOMY` | `TEST` | `LAB_VALUE` | `AGE` | `GENDER` | `FREQUENCY`\n",
    "\n",
    "---\n",
    "**‚öôÔ∏è Recommended Colab Settings:**\n",
    "- Runtime ‚Üí Change runtime type ‚Üí GPU (Tesla T4)\n",
    "- Edit ‚Üí Notebook settings ‚Üí GPU hardware accelerator\n",
    "\n",
    "**üì¶ Model:** CamemBERT-ner (French medical BERT)  \n",
    "**‚è±Ô∏è Training Time:** ~15-20 minutes on Tesla T4  \n",
    "**üéì Perfect for:** Academic projects, medical document processing, research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9605a62f",
   "metadata": {},
   "source": [
    "## üîß Step 1: Environment Setup & GPU Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faafab2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üîç ENVIRONMENT VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Python version\n",
    "print(f\"\\nüêç Python Version: {sys.version.split()[0]}\")\n",
    "\n",
    "# PyTorch version\n",
    "print(f\"üî• PyTorch Version: {torch.__version__}\")\n",
    "\n",
    "# GPU detection\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\n‚úÖ GPU AVAILABLE!\")\n",
    "    print(f\"   ‚îú‚îÄ Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   ‚îú‚îÄ Compute Capability: {torch.cuda.get_device_capability(0)}\")\n",
    "    print(f\"   ‚îú‚îÄ Total Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"   ‚îî‚îÄ CUDA Version: {torch.version.cuda}\")\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "    # Memory check\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"\\nüíæ GPU Memory Status:\")\n",
    "    print(f\"   ‚îú‚îÄ Allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
    "    print(f\"   ‚îî‚îÄ Reserved: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  NO GPU DETECTED!\")\n",
    "    print(f\"   ‚îî‚îÄ Training will be extremely slow. Enable GPU in Runtime settings!\")\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"\\nüéØ Selected Device: {device}\")\n",
    "print(f\"‚è∞ Start Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ea071e",
   "metadata": {},
   "source": [
    "## üì¶ Step 2: Install Dependencies\n",
    "\n",
    "Installing state-of-the-art NLP libraries optimized for token classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d988982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture install_output\n",
    "!pip install -q transformers==4.37.0 datasets==2.16.1 accelerate==0.26.1 seqeval==1.2.2 scikit-learn matplotlib\n",
    "\n",
    "# Show installation summary\n",
    "print(\"‚úÖ Installation Complete!\")\n",
    "print(\"\\nüì¶ Installed Packages:\")\n",
    "print(\"   ‚îú‚îÄ transformers: 4.37.0 (Hugging Face)\")\n",
    "print(\"   ‚îú‚îÄ datasets: 2.16.1 (Data processing)\")\n",
    "print(\"   ‚îú‚îÄ accelerate: 0.26.1 (Training optimization)\")\n",
    "print(\"   ‚îú‚îÄ seqeval: 1.2.2 (NER metrics)\")\n",
    "print(\"   ‚îú‚îÄ scikit-learn (ML utilities)\")\n",
    "print(\"   ‚îî‚îÄ matplotlib (Visualization)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0545e4",
   "metadata": {},
   "source": [
    "## üîÑ Step 3: Import Libraries & Set Random Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b0ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "from collections import Counter\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# Transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "\n",
    "# Data processing\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Metrics\n",
    "from seqeval.metrics import (\n",
    "    classification_report as seqeval_report,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Set random seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(\"‚úÖ Random seeds set for reproducibility (seed=42)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ac2115",
   "metadata": {},
   "source": [
    "## üè∑Ô∏è Step 4: Define Enhanced Entity Labels (12 Types)\n",
    "\n",
    "Extended label set for comprehensive medical entity extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df4696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIO tagging format (Beginning, Inside, Outside)\n",
    "# 12 entity types for comprehensive medical NER\n",
    "labels = [\n",
    "    'O',  # Outside any entity\n",
    "    'B-DISEASE', 'I-DISEASE',           # Diseases, conditions\n",
    "    'B-MEDICATION', 'I-MEDICATION',     # Drugs, medicines\n",
    "    'B-SYMPTOM', 'I-SYMPTOM',           # Symptoms, signs\n",
    "    'B-DOSAGE', 'I-DOSAGE',             # Medication dosages, frequencies\n",
    "    'B-DATE', 'I-DATE',                 # Dates, temporal expressions\n",
    "    'B-PROCEDURE', 'I-PROCEDURE',       # Medical procedures, surgeries\n",
    "    'B-ANATOMY', 'I-ANATOMY',           # Body parts, organs\n",
    "    'B-TEST', 'I-TEST',                 # Lab tests, imaging\n",
    "    'B-LAB_VALUE', 'I-LAB_VALUE',       # Lab result values\n",
    "    'B-AGE', 'I-AGE',                   # Patient age\n",
    "    'B-GENDER', 'I-GENDER',             # Patient gender\n",
    "    'B-FREQUENCY', 'I-FREQUENCY'        # Medication frequency\n",
    "]\n",
    "\n",
    "label2id = {label: idx for idx, label in enumerate(labels)}\n",
    "id2label = {idx: label for idx, label in enumerate(labels)}\n",
    "\n",
    "# Entity categories for reporting\n",
    "entity_types = ['DISEASE', 'MEDICATION', 'SYMPTOM', 'DOSAGE', 'DATE', \n",
    "                'PROCEDURE', 'ANATOMY', 'TEST', 'LAB_VALUE', 'AGE', \n",
    "                'GENDER', 'FREQUENCY']\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üè∑Ô∏è  ENHANCED LABEL SCHEMA\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìä Total labels: {len(labels)} (BIO format)\")\n",
    "print(f\"üìä Entity types: {len(entity_types)}\")\n",
    "print(f\"\\nüéØ Entity Categories:\")\n",
    "for i, entity in enumerate(entity_types, 1):\n",
    "    print(f\"   {i:2d}. {entity}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Label mappings created!\")\n",
    "print(f\"   ‚îú‚îÄ label2id: {len(label2id)} mappings\")\n",
    "print(f\"   ‚îî‚îÄ id2label: {len(id2label)} mappings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61a98b3",
   "metadata": {},
   "source": [
    "## üìù Step 5: Create Comprehensive Training Dataset (100+ Samples)\n",
    "\n",
    "High-quality annotated French medical texts with diverse clinical scenarios."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
