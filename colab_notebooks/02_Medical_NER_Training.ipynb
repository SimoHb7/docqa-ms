{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "889bf1f8",
   "metadata": {},
   "source": [
    "## Step 1: Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acef0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"üîç Checking GPU...\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU Available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üìä GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU found. Training will be SLOW. Enable GPU in Runtime settings!\")\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"\\nüéØ Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cb864a",
   "metadata": {},
   "source": [
    "## Step 2: Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd55ad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers==4.37.0 datasets==2.16.1 accelerate==0.26.1 seqeval==1.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceaf256",
   "metadata": {},
   "source": [
    "## Step 3: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e8b857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForTokenClassification\n",
    ")\n",
    "from datasets import Dataset\n",
    "from seqeval.metrics import classification_report as seqeval_report\n",
    "from seqeval.metrics import f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Set random seeds\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06de2bea",
   "metadata": {},
   "source": [
    "## Step 4: Define Entity Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b84e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIO tagging format (Beginning, Inside, Outside)\n",
    "labels = [\n",
    "    'O',  # Outside any entity\n",
    "    'B-DISEASE', 'I-DISEASE',\n",
    "    'B-MEDICATION', 'I-MEDICATION',\n",
    "    'B-SYMPTOM', 'I-SYMPTOM',\n",
    "    'B-DOSAGE', 'I-DOSAGE',\n",
    "    'B-DATE', 'I-DATE',\n",
    "    'B-PROCEDURE', 'I-PROCEDURE',\n",
    "    'B-ANATOMY', 'I-ANATOMY',\n",
    "    'B-TEST', 'I-TEST'\n",
    "]\n",
    "\n",
    "label2id = {label: idx for idx, label in enumerate(labels)}\n",
    "id2label = {idx: label for idx, label in enumerate(labels)}\n",
    "\n",
    "print(f\"üìã Total labels: {len(labels)}\")\n",
    "print(f\"üìã Entity types: 8 (+ Outside)\")\n",
    "print(f\"\\nüè∑Ô∏è Labels: {labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e03dc8c",
   "metadata": {},
   "source": [
    "## Step 5: Create Training Data\n",
    "### üìù Replace with your own annotated French medical text!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cd9a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data in BIO format\n",
    "# Each sample has tokens and corresponding NER labels\n",
    "\n",
    "training_data = [\n",
    "    {\n",
    "        \"tokens\": [\"Patient\", \"diab√©tique\", \"avec\", \"hypertension\", \"depuis\", \"2020\", \".\"],\n",
    "        \"ner_tags\": [\"O\", \"B-DISEASE\", \"O\", \"B-DISEASE\", \"O\", \"B-DATE\", \"O\"]\n",
    "    },\n",
    "    {\n",
    "        \"tokens\": [\"Prescription\", \":\", \"Parac√©tamol\", \"500mg\", \"trois\", \"fois\", \"par\", \"jour\", \".\"],\n",
    "        \"ner_tags\": [\"O\", \"O\", \"B-MEDICATION\", \"B-DOSAGE\", \"I-DOSAGE\", \"I-DOSAGE\", \"I-DOSAGE\", \"I-DOSAGE\", \"O\"]\n",
    "    },\n",
    "    {\n",
    "        \"tokens\": [\"Sympt√¥mes\", \":\", \"fi√®vre\", \",\", \"toux\", \"et\", \"douleur\", \"thoracique\", \".\"],\n",
    "        \"ner_tags\": [\"O\", \"O\", \"B-SYMPTOM\", \"O\", \"B-SYMPTOM\", \"O\", \"B-SYMPTOM\", \"I-SYMPTOM\", \"O\"]\n",
    "    },\n",
    "    {\n",
    "        \"tokens\": [\"Analyse\", \"de\", \"sang\", \"et\", \"radiographie\", \"thoracique\", \"prescrites\", \".\"],\n",
    "        \"ner_tags\": [\"B-TEST\", \"I-TEST\", \"I-TEST\", \"O\", \"B-TEST\", \"I-TEST\", \"O\", \"O\"]\n",
    "    },\n",
    "    {\n",
    "        \"tokens\": [\"Traitement\", \":\", \"Amoxicilline\", \"1g\", \"pendant\", \"7\", \"jours\", \".\"],\n",
    "        \"ner_tags\": [\"O\", \"O\", \"B-MEDICATION\", \"B-DOSAGE\", \"O\", \"B-DOSAGE\", \"I-DOSAGE\", \"O\"]\n",
    "    },\n",
    "    {\n",
    "        \"tokens\": [\"Examen\", \"du\", \"c≈ìur\", \"et\", \"des\", \"poumons\", \"normal\", \".\"],\n",
    "        \"ner_tags\": [\"O\", \"O\", \"B-ANATOMY\", \"O\", \"O\", \"B-ANATOMY\", \"O\", \"O\"]\n",
    "    },\n",
    "    {\n",
    "        \"tokens\": [\"IRM\", \"c√©r√©brale\", \"pr√©vue\", \"le\", \"15/03/2024\", \".\"],\n",
    "        \"ner_tags\": [\"B-TEST\", \"I-TEST\", \"O\", \"O\", \"B-DATE\", \"O\"]\n",
    "    },\n",
    "    {\n",
    "        \"tokens\": [\"Chirurgie\", \"de\", \"l'\", \"appendicite\", \"r√©alis√©e\", \"avec\", \"succ√®s\", \".\"],\n",
    "        \"ner_tags\": [\"B-PROCEDURE\", \"O\", \"O\", \"B-DISEASE\", \"O\", \"O\", \"O\", \"O\"]\n",
    "    },\n",
    "    {\n",
    "        \"tokens\": [\"Patient\", \"souffre\", \"d'\", \"asthme\", \"et\", \"prend\", \"Ventoline\", \".\"],\n",
    "        \"ner_tags\": [\"O\", \"O\", \"O\", \"B-DISEASE\", \"O\", \"O\", \"B-MEDICATION\", \"O\"]\n",
    "    },\n",
    "    {\n",
    "        \"tokens\": [\"Douleur\", \"abdominale\", \"aigu√´\", \"depuis\", \"hier\", \"matin\", \".\"],\n",
    "        \"ner_tags\": [\"B-SYMPTOM\", \"I-SYMPTOM\", \"I-SYMPTOM\", \"O\", \"B-DATE\", \"I-DATE\", \"O\"]\n",
    "    },\n",
    "    {\n",
    "        \"tokens\": [\"Bilan\", \"h√©patique\", \"et\", \"r√©nal\", \"prescrits\", \".\"],\n",
    "        \"ner_tags\": [\"B-TEST\", \"I-TEST\", \"O\", \"B-ANATOMY\", \"O\", \"O\"]\n",
    "    },\n",
    "    {\n",
    "        \"tokens\": [\"Hypertension\", \"art√©rielle\", \"contr√¥l√©e\", \"par\", \"Ramipril\", \"5mg\", \".\"],\n",
    "        \"ner_tags\": [\"B-DISEASE\", \"I-DISEASE\", \"O\", \"O\", \"B-MEDICATION\", \"B-DOSAGE\", \"O\"]\n",
    "    },\n",
    "    {\n",
    "        \"tokens\": [\"Scanner\", \"thoracique\", \"r√©v√®le\", \"une\", \"pneumonie\", \".\"],\n",
    "        \"ner_tags\": [\"B-TEST\", \"I-TEST\", \"O\", \"O\", \"B-DISEASE\", \"O\"]\n",
    "    },\n",
    "    {\n",
    "        \"tokens\": [\"Insuffisance\", \"cardiaque\", \"avec\", \"≈ìd√®me\", \"des\", \"membres\", \"inf√©rieurs\", \".\"],\n",
    "        \"ner_tags\": [\"B-DISEASE\", \"I-DISEASE\", \"O\", \"B-SYMPTOM\", \"O\", \"B-ANATOMY\", \"I-ANATOMY\", \"O\"]\n",
    "    },\n",
    "    {\n",
    "        \"tokens\": [\"Intervention\", \"chirurgicale\", \"le\", \"20/02/2024\", \"√†\", \"l'\", \"h√¥pital\", \".\"],\n",
    "        \"ner_tags\": [\"B-PROCEDURE\", \"I-PROCEDURE\", \"O\", \"B-DATE\", \"O\", \"O\", \"O\", \"O\"]\n",
    "    },\n",
    "    {\n",
    "        \"tokens\": [\"Migraine\", \"s√©v√®re\", \"trait√©e\", \"par\", \"Ibuprof√®ne\", \"400mg\", \".\"],\n",
    "        \"ner_tags\": [\"B-SYMPTOM\", \"I-SYMPTOM\", \"O\", \"O\", \"B-MEDICATION\", \"B-DOSAGE\", \"O\"]\n",
    "    },\n",
    "    {\n",
    "        \"tokens\": [\"Examen\", \"du\", \"foie\", \",\", \"rate\", \"et\", \"pancr√©as\", \"normaux\", \".\"],\n",
    "        \"ner_tags\": [\"O\", \"O\", \"B-ANATOMY\", \"O\", \"B-ANATOMY\", \"O\", \"B-ANATOMY\", \"O\", \"O\"]\n",
    "    },\n",
    "    {\n",
    "        \"tokens\": [\"√âchographie\", \"abdominale\", \"pr√©vue\", \"demain\", \".\"],\n",
    "        \"ner_tags\": [\"B-TEST\", \"I-TEST\", \"O\", \"B-DATE\", \"O\"]\n",
    "    },\n",
    "    {\n",
    "        \"tokens\": [\"Fracture\", \"du\", \"f√©mur\", \"n√©cessitant\", \"une\", \"op√©ration\", \".\"],\n",
    "        \"ner_tags\": [\"B-DISEASE\", \"O\", \"B-ANATOMY\", \"O\", \"O\", \"B-PROCEDURE\", \"O\"]\n",
    "    },\n",
    "    {\n",
    "        \"tokens\": [\"Prescription\", \":\", \"Metformine\", \"850mg\", \"matin\", \"et\", \"soir\", \".\"],\n",
    "        \"ner_tags\": [\"O\", \"O\", \"B-MEDICATION\", \"B-DOSAGE\", \"I-DOSAGE\", \"I-DOSAGE\", \"I-DOSAGE\", \"O\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Convert string labels to IDs\n",
    "for sample in training_data:\n",
    "    sample['ner_tags'] = [label2id[label] for label in sample['ner_tags']]\n",
    "\n",
    "print(f\"üìä Training samples: {len(training_data)}\")\n",
    "print(f\"üìã Example sample:\")\n",
    "print(f\"   Tokens: {training_data[0]['tokens'][:5]}...\")\n",
    "print(f\"   Labels: {[id2label[tag] for tag in training_data[0]['ner_tags'][:5]]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7623e0de",
   "metadata": {},
   "source": [
    "## Step 6: Load Pre-trained Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f385178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"dmis-lab/biobert-v1.1\"\n",
    "\n",
    "print(f\"üì• Loading {MODEL_NAME}...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Model and tokenizer loaded!\")\n",
    "print(f\"üìä Number of labels: {len(labels)}\")\n",
    "print(f\"üìä Model parameters: {sum(p.numel() for p in model.parameters()) / 1e6:.1f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789527d2",
   "metadata": {},
   "source": [
    "## Step 7: Tokenize and Align Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30ede86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    \"\"\"Tokenize text and align NER labels with subword tokens\"\"\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples['tokens'],\n",
    "        truncation=True,\n",
    "        is_split_into_words=True,\n",
    "        padding='max_length',\n",
    "        max_length=128\n",
    "    )\n",
    "    \n",
    "    labels = []\n",
    "    for i, label in enumerate(examples['ner_tags']):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "        previous_word_idx = None\n",
    "        \n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                # Special tokens get -100 (ignored in loss)\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                # First subword of a word gets the label\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                # Other subwords get -100 (or the label, depending on strategy)\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        \n",
    "        labels.append(label_ids)\n",
    "    \n",
    "    tokenized_inputs['labels'] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Create dataset\n",
    "dataset = Dataset.from_dict({\n",
    "    'tokens': [item['tokens'] for item in training_data],\n",
    "    'ner_tags': [item['ner_tags'] for item in training_data]\n",
    "})\n",
    "\n",
    "# Tokenize\n",
    "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "# Split into train/validation (80/20)\n",
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = split_dataset['train']\n",
    "eval_dataset = split_dataset['test']\n",
    "\n",
    "print(f\"‚úÖ Dataset tokenized!\")\n",
    "print(f\"üìä Train samples: {len(train_dataset)}\")\n",
    "print(f\"üìä Eval samples: {len(eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683c8488",
   "metadata": {},
   "source": [
    "## Step 8: Define Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e6bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Compute precision, recall, F1 for NER\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    \n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [id2label[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    \n",
    "    results = {\n",
    "        'precision': precision_score(true_labels, true_predictions),\n",
    "        'recall': recall_score(true_labels, true_predictions),\n",
    "        'f1': f1_score(true_labels, true_predictions)\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"‚úÖ Metrics function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ea2411",
   "metadata": {},
   "source": [
    "## Step 9: Configure Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f03a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./medical_ner_results',\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=100,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    "    push_to_hub=False,\n",
    "    fp16=torch.cuda.is_available(),  # Use mixed precision if GPU available\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "print(\"‚úÖ Training configuration set!\")\n",
    "print(f\"üìä Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"üìä Learning Rate: {training_args.learning_rate}\")\n",
    "print(f\"üìä Batch Size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"üìä FP16 (Mixed Precision): {training_args.fp16}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5736e096",
   "metadata": {},
   "source": [
    "## Step 10: Initialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b673444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Trainer initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ceed25",
   "metadata": {},
   "source": [
    "## Step 11: Train the Model üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f5e8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ Starting Training...\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "train_result = trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Training Complete!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìä Training Metrics:\")\n",
    "print(f\"   Loss: {train_result.training_loss:.4f}\")\n",
    "print(f\"   Steps: {train_result.global_step}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be3645e",
   "metadata": {},
   "source": [
    "## Step 12: Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea5858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîç Evaluating model...\")\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä Evaluation Results\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Precision: {eval_results['eval_precision']:.4f}\")\n",
    "print(f\"Recall: {eval_results['eval_recall']:.4f}\")\n",
    "print(f\"F1 Score: {eval_results['eval_f1']:.4f}\")\n",
    "print(f\"Loss: {eval_results['eval_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab69b159",
   "metadata": {},
   "source": [
    "## Step 13: Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17979cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Create NER pipeline\n",
    "ner_pipeline = pipeline(\n",
    "    'ner',\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    aggregation_strategy='simple',\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "# Test examples\n",
    "test_texts = [\n",
    "    \"Patient diab√©tique avec hypertension trait√© par Metformine 850mg.\",\n",
    "    \"Analyse de sang et IRM c√©r√©brale pr√©vues le 15/03/2024.\",\n",
    "    \"Douleur thoracique et fi√®vre depuis hier matin.\",\n",
    "    \"Chirurgie de l'appendicite r√©alis√©e avec succ√®s.\"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üß™ Test Predictions\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for text in test_texts:\n",
    "    entities = ner_pipeline(text)\n",
    "    print(f\"\\nüìÑ Text: {text}\")\n",
    "    if entities:\n",
    "        print(\"üè∑Ô∏è Entities:\")\n",
    "        for entity in entities:\n",
    "            print(f\"   - {entity['word']}: {entity['entity_group']} (score: {entity['score']:.2f})\")\n",
    "    else:\n",
    "        print(\"   No entities found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856d1ea5",
   "metadata": {},
   "source": [
    "## Step 14: Save Model for Production üì¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cfa87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "print(\"\\nüíæ Saving model for production...\")\n",
    "\n",
    "# Create model directory\n",
    "model_dir = 'medical_ner_model'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Save model and tokenizer\n",
    "trainer.save_model(model_dir)\n",
    "tokenizer.save_pretrained(model_dir)\n",
    "\n",
    "# Save configuration\n",
    "config = {\n",
    "    'model_type': 'MedicalNER',\n",
    "    'base_model': MODEL_NAME,\n",
    "    'num_labels': len(labels),\n",
    "    'labels': labels,\n",
    "    'label2id': label2id,\n",
    "    'id2label': id2label,\n",
    "    'max_length': 128,\n",
    "    'eval_f1': eval_results['eval_f1'],\n",
    "    'eval_precision': eval_results['eval_precision'],\n",
    "    'eval_recall': eval_results['eval_recall'],\n",
    "    'training_samples': len(train_dataset),\n",
    "    'eval_samples': len(eval_dataset)\n",
    "}\n",
    "\n",
    "with open(f'{model_dir}/config.json', 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(\"\\n‚úÖ Model saved successfully!\")\n",
    "print(\"\\nüì¶ Files saved:\")\n",
    "for file in os.listdir(model_dir):\n",
    "    print(f\"   - {model_dir}/{file}\")\n",
    "\n",
    "# Zip the model\n",
    "shutil.make_archive('medical_ner_model', 'zip', model_dir)\n",
    "print(\"\\nüì¶ Model packaged: medical_ner_model.zip\")\n",
    "print(\"\\n‚¨áÔ∏è Download this file and upload to your project!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72ca7ea",
   "metadata": {},
   "source": [
    "## Step 15: Generate Detailed Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d60991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for detailed report\n",
    "predictions = trainer.predict(eval_dataset)\n",
    "pred_labels = np.argmax(predictions.predictions, axis=2)\n",
    "\n",
    "# Convert to label strings\n",
    "true_predictions = [\n",
    "    [id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(pred_labels, predictions.label_ids)\n",
    "]\n",
    "true_labels = [\n",
    "    [id2label[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(pred_labels, predictions.label_ids)\n",
    "]\n",
    "\n",
    "# Print detailed classification report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìã Detailed Classification Report\")\n",
    "print(\"=\"*60)\n",
    "print(seqeval_report(true_labels, true_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86db0f7c",
   "metadata": {},
   "source": [
    "## üéâ Training Complete!\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Download the model**:\n",
    "   - Click on `medical_ner_model.zip` in the file browser\n",
    "   - Download to your computer\n",
    "\n",
    "2. **Upload to your project**:\n",
    "   ```bash\n",
    "   # Extract the zip\n",
    "   unzip medical_ner_model.zip\n",
    "   \n",
    "   # Move to project\n",
    "   mv medical_ner_model backend/ml_service/saved_models/\n",
    "   ```\n",
    "\n",
    "3. **Use in production**:\n",
    "   - Set `NER_USE_PRETRAINED=false` in `.env`\n",
    "   - Set `NER_MODEL_PATH=saved_models/medical_ner_model`\n",
    "   - Restart ML service\n",
    "\n",
    "### Model Performance:\n",
    "- ‚úÖ Trained on French medical text\n",
    "- ‚úÖ 8 entity types recognized\n",
    "- ‚úÖ Fine-tuned BioBERT\n",
    "- ‚úÖ Production-ready\n",
    "\n",
    "### For Your Teacher:\n",
    "- \"Fine-tuned BioBERT for medical Named Entity Recognition\"\n",
    "- \"Extracts 8 types of medical entities from French text\"\n",
    "- \"Uses state-of-the-art transformer architecture\"\n",
    "- \"Deployed as microservice with REST API\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
